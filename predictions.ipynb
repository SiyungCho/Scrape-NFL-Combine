{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                704       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11265 (44.00 KB)\n",
      "Trainable params: 11265 (44.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('combine_prediction_model.keras')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_values = input(\"Please input combine stats in this format\\n(POS, Height (in), Weight (lbs), 40 Yard, Bench Press, Vertical Leap (in), Broad Jump (in), Shuttle, 3 Cone)\\nEnsure no spaces in between values only seperating values with a comma:\\n\")\n",
    "player_values_list = player_values.split(\",\")\n",
    "\n",
    "player_POS, player_Height, player_Weight, player_40Yard, player_BenchPress, player_Vert, player_Broad, player_Shuttle, player_3Cone = player_values_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WR\n"
     ]
    }
   ],
   "source": [
    "print(player_POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#player_POS = 'CB'\n",
    "#player_Height = 74.75\n",
    "#player_Weight = 190\n",
    "#player_40Yard = 4.41\n",
    "#player_BenchPress = 21\n",
    "#player_Vert = 32.5\n",
    "#player_Broad = 118\n",
    "#player_Shuttle = 4.51\n",
    "#player_3Cone = 7.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "holder_df = pd.DataFrame(columns=['POS', \"Height (in)\", \"Weight (lbs)\", \"40 Yard\", \"Bench Press\", \"Vert Leap (in)\", \"Broad Jump (in)\", \"Shuttle\", \"3Cone\"])\n",
    "new_entry = pd.DataFrame({'POS': [player_POS], \"Height (in)\": [float(player_Height)], \"Weight (lbs)\": [float(player_Weight)], \"40 Yard\": [float(player_40Yard)], \"Bench Press\": [float(player_BenchPress)], \"Vert Leap (in)\": [float(player_Vert)], \"Broad Jump (in)\": [float(player_Broad)], \"Shuttle\": [float(player_Shuttle)], \"3Cone\": [float(player_3Cone)]})\n",
    "holder_df = pd.concat([holder_df,new_entry], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = pd.read_csv('sampled_data.csv')\n",
    "sampled_df = sampled_df.drop(columns=[\"Pro Bowl\"])\n",
    "pred_df = pd.concat([sampled_df, holder_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  POS  Height (in)  Weight (lbs)  40 Yard  Bench Press  Vert Leap (in)  \\\n",
      "0  OT        78.00         321.0     5.41         20.0            29.0   \n",
      "1  LB        73.00         235.0     4.70         24.0            33.5   \n",
      "2  CB        71.00         193.0     4.56          9.0            32.0   \n",
      "3  OT        78.50         290.0     5.20         22.0            25.0   \n",
      "4  RB        71.13         208.0     4.39         15.0            37.0   \n",
      "\n",
      "   Broad Jump (in)  Shuttle  3Cone  \n",
      "0            102.0     4.90   8.23  \n",
      "1            114.0     4.33   7.31  \n",
      "2            114.0     4.29   7.31  \n",
      "3             99.0     4.83   7.31  \n",
      "4            121.0     4.39   7.18  \n"
     ]
    }
   ],
   "source": [
    "print(pred_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_col = ['POS']\n",
    "encoder = OneHotEncoder()\n",
    "encoded_features = encoder.fit_transform(pred_df[categorical_col]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_col = [\"Height (in)\", \"Weight (lbs)\", \"40 Yard\", \"Bench Press\", \"Vert Leap (in)\", \"Broad Jump (in)\", \"Shuttle\", \"3Cone\"]\n",
    "scalar = StandardScaler()\n",
    "scaled_numerical_features = scalar.fit_transform(pred_df[numerical_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0    1    2    3    4    5    6    7    8    9   ...   11   12        0   \\\n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  1.591878   \n",
      "1  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0 -0.308349   \n",
      "2  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0 -1.068439   \n",
      "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  1.781900   \n",
      "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0  0.0 -1.019033   \n",
      "\n",
      "         1         2         3         4         5         6         7   \n",
      "0  1.819784  2.224586 -0.011419 -0.923683 -1.440537  2.249537  3.096946  \n",
      "1 -0.119642 -0.295699  0.695189  0.206501 -0.035737 -0.287157  0.086990  \n",
      "2 -1.066803 -0.792656 -1.954589 -0.170227 -0.035737 -0.465171  0.086990  \n",
      "3  1.120689  1.479149  0.341885 -1.928291 -1.791737  1.938014  0.086990  \n",
      "4 -0.728531 -1.396105 -0.894678  1.085534  0.783730 -0.020137 -0.338329  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "pred_data = pd.concat([pd.DataFrame(encoded_features), pd.DataFrame(scaled_numerical_features)], axis=1)\n",
    "print(pred_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2    3    4    5    6    7    8    9    10   11   12        0        1         2         3        4         5         6        7 \n",
      "1840  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 -0.213337 -0.86384 -1.254117 -0.011419  1.21111  1.369063  0.291387  0.08699\n"
     ]
    }
   ],
   "source": [
    "pred_input = pred_data.tail(1)\n",
    "print(pred_input.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_predict = np.array(pred_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n",
      "prediction: [[0.55585146]]\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_predict)\n",
    "print(\"prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2020,WR,73.5,208,4.59,20,31.5,117,4.42,7.31\n",
    "#2020,WR,73.25,202,4.43,20,37.5,126,4.46,7.31\n",
    "#2022,RB,72.38,211,4.48,21,30.0,117,4.51,7.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2021,WR,71.5,197,4.61,20,38.5,127,4.26,6.9,1\n",
    "#2021,WR,70.13,180,4.48,20,33.0,122,4.21,6.86,0\n",
    "#2021,WR,75.0,211,4.49,12,37.0,124,4.43,7.2,0\n",
    "#2021,WR,72.75,203,4.47,17,40.0,124,4.14,7.02,0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
